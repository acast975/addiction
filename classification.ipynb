{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandar.stanimirovic/.virtualenvs/addiction/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/Users/aleksandar.stanimirovic/.virtualenvs/addiction/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading raw data from dataset\n",
    "raw_data = pandas.read_csv('./datasets/addict-fix-limit.csv')\n",
    "\n",
    "# convert everything to numeric data\n",
    "# missing value are replaced with NoN\n",
    "for column in raw_data.columns:\n",
    "    raw_data[column] = pandas.to_numeric(raw_data[column], errors='coerce')\n",
    "\n",
    "# drop all rows where PUIcutoof column is NoN\n",
    "raw_data = raw_data.dropna(subset=['PUIcutoff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    column for column in raw_data.columns\n",
    "    if not column.startswith('TEMPS')\n",
    "    and not column.startswith('Internet')\n",
    "    and not column.startswith('Sadrzaj')\n",
    "    and not column.startswith('Aktivnost')\n",
    "    and column not in ['ID', 'EnergetskoPml', 'NemaFB', 'KolikoCigareta', 'NeZnaNet','SkolaPoRegionu', 'FBupotreba', 'PROT_SADR_AKT', 'RISK_SADR_AKT', 'Temper_bin', 'NKP', 'PI', 'SPO', 'PUI', 'PUIcutoff']\n",
    "]\n",
    "\n",
    "# class column for binary classification of addiction                 ]\n",
    "class_name = 'PUIcutoff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of relevant features (Pearson correlation > 0.3\n",
      "PUIcutoff            1.000000\n",
      "Uspeh                0.181068\n",
      "KolikoNedeljno       0.309938\n",
      "KolikNajduze         0.210148\n",
      "DaMozeDaLiBi         0.239064\n",
      "DaLiSvakodnevnoFb    0.177286\n",
      "BrojaSatiFB          0.191674\n",
      "EnergetskoP          0.144596\n",
      "Alkohol_bin          0.126921\n",
      "Depresivan           0.177879\n",
      "Ciklotimicni         0.270440\n",
      "Iritabilni           0.209510\n",
      "Anksiozni            0.174712\n",
      "Name: PUIcutoff, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# calculate Pearson Correlation for all columns \n",
    "corr_data = raw_data[feature_names]                                       \n",
    "corr_data.insert(0, class_name, raw_data[class_name].to_numpy())                             \n",
    "cor = corr_data.corr()\n",
    "\n",
    "cor_target = abs(cor['PUIcutoff'])                           \n",
    "relevant_features = cor_target[cor_target > 0.1]             \n",
    "print('List of relevant features (Pearson correlation > 0.3')\n",
    "print(relevant_features)                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between individual columns\n",
      "Person correlation between columns BrojDana and IntenzitetFizAkt: 0.5959313943430498\n",
      "Person correlation between columns IntenzitetFizAkt and BrojDana: 0.5959313943430498\n",
      "Person correlation between columns IntenzitetFizAkt and KolikoTrajeAkt: 0.5319552918386935\n",
      "Person correlation between columns KolikoTrajeAkt and IntenzitetFizAkt: 0.5319552918386935\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation between individual columns')\n",
    "for column_i in corr_data.columns:                                                                                               \n",
    "    for column_j in corr_data.columns:                                                                                           \n",
    "        if column_i != column_j:                                                                                                 \n",
    "            column_corr = corr_data[[column_i, column_j]].corr()                                                                 \n",
    "            if abs(column_corr.iloc[0].iloc[1]) > 0.5:                                                                           \n",
    "                print(\"Person correlation between columns {} and {}: {}\".format(column_i, column_j, column_corr.iloc[0].iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_raw = raw_data[feature_names]                                                     \n",
    "class_data = raw_data[class_name]                                                              \n",
    "                                                                                               \n",
    "# preprocessing data                                                                           \n",
    "                                                                                               \n",
    "imputer = SimpleImputer(missing_values=numpy.nan, strategy='most_frequent')                    \n",
    "imputed_data = imputer.fit_transform(feature_data_raw)                                         \n",
    "                                                                                               \n",
    "scaler = StandardScaler()                                                                      \n",
    "scaled_data = scaler.fit_transform(imputed_data)                                               \n",
    "                                                                                               \n",
    "feature_data_processed = pandas.DataFrame(scaled_data)                                         \n",
    "feature_data_processed.columns = feature_data_raw.columns                                      \n",
    "                                                                                               \n",
    "# split data to trainig and test set (30% test set)                                            \n",
    "train_feature_data, test_feature_data, train_class_data, test_class_data = train_test_split(feature_data_processed, class_data, test_size=0.3, stratify=class_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification using LogisticRegression                                     \n",
    "print('Logistic Regression classifier')                                       \n",
    "# create model using training data                                            \n",
    "classifier = LogisticRegression(max_iter=10000, solver='lbfgs')               \n",
    "classifier.fit(train_feature_data, train_class_data)                          \n",
    "                                                                              \n",
    "# predict using model and test data                                           \n",
    "test_predicted_data = classifier.predict(test_feature_data)                   \n",
    "                                                                              \n",
    "# calculatre metrics                                                          \n",
    "print('score={}'.format(accuracy_score(test_class_data, test_predicted_data)))\n",
    "print(confusion_matrix(test_class_data, test_predicted_data))                 \n",
    "print(classification_report(test_class_data, test_predicted_data))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using RFE (Recursive Feature Estimation)                                            \n",
    "print('Logistic Regression classifier after using RFE')                               \n",
    "classifier = LogisticRegression(max_iter=10000, solver='lbfgs')                       \n",
    "rfe = RFE(classifier, 15)                                                             \n",
    "                                                                                      \n",
    "                                                                                      \n",
    "rfe_data = rfe.fit_transform(feature_data_processed, class_data)                      \n",
    "selected_columns = rfe.get_support(indices=True)                                      \n",
    "                                                                                      \n",
    "columns_rfe = [                                                                       \n",
    "    feature_data_processed.columns[selected] for selected in selected_columns         \n",
    "]                                                                                     \n",
    "                                                                                      \n",
    "print('RFE selected columns {}'.format(columns_rfe))                                  \n",
    "                                                                                      \n",
    "feature_data_rfe = pandas.DataFrame(rfe_data)                                         \n",
    "feature_data_rfe.columns = columns_rfe                                                \n",
    "                                                                                      \n",
    "# split rfe data to trainig and test set (30% test set)                               \n",
    "train_feature_data, test_feature_data, train_class_data, test_class_data = train_test_split(feature_data_rfe, class_data, test_size=0.3, stratify=class_data)\n",
    "                                                                                      \n",
    "classifier.fit(train_feature_data, train_class_data)                                  \n",
    "                                                                                      \n",
    "# predict using model and test data                                                   \n",
    "test_predicted_data = classifier.predict(test_feature_data)                           \n",
    "                                                                                      \n",
    "# calculatre metrics                                                                  \n",
    "print('score={}'.format(accuracy_score(test_class_data, test_predicted_data)))        \n",
    "print(confusion_matrix(test_class_data, test_predicted_data))                         \n",
    "print(classification_report(test_class_data, test_predicted_data))                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using RFE (Recursive Feature Estimation)                                               \n",
    "print('Logistic Regression classifier after using RFECV')                                \n",
    "classifier = LogisticRegression(max_iter=10000, solver='lbfgs')                          \n",
    "rfecv = RFECV(estimator=classifier, step=1, cv=StratifiedKFold(2), scoring='accuracy')   \n",
    "                                                                                         \n",
    "rfecv_data = rfecv.fit_transform(feature_data_processed, class_data)                     \n",
    "                                                                                         \n",
    "# Plot number of features VS. cross-validation scores                                    \n",
    "plot.figure()                                                                            \n",
    "plot.xlabel(\"Number of features selected\")                                               \n",
    "plot.ylabel(\"Cross validation score (nb of correct classifications)\")                    \n",
    "plot.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)                     \n",
    "plot.show()                                                                              \n",
    "                                                                                         \n",
    "selected_columns = rfecv.get_support(indices=True)                                       \n",
    "columns_rfecv = [                                                                        \n",
    "    feature_data_processed.columns[selected] for selected in selected_columns            \n",
    "]                                                                                        \n",
    "                                                                                         \n",
    "print('RFECV selected columns {}'.format(columns_rfe))                                   \n",
    "                                                                                         \n",
    "feature_data_rfecv = pandas.DataFrame(rfecv_data)                                        \n",
    "feature_data_rfecv.columns = columns_rfecv                                               \n",
    "                                                                                         \n",
    "# split rfe data to trainig and test set (30% test set)                                  \n",
    "train_feature_data, test_feature_data, train_class_data, test_class_data = train_test_split(feature_data_rfecv, class_data, test_size=0.3, stratify=class_data) \n",
    "                                                                                         \n",
    "classifier.fit(train_feature_data, train_class_data)                                     \n",
    "                                                                                         \n",
    "# predict using model and test data                                                      \n",
    "test_predicted_data = classifier.predict(test_feature_data)                              \n",
    "                                                                                         \n",
    "# calculatre metrics                                                                     \n",
    "print('score={}'.format(accuracy_score(test_class_data, test_predicted_data)))           \n",
    "print(confusion_matrix(test_class_data, test_predicted_data))                            \n",
    "print(classification_report(test_class_data, test_predicted_data))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using LassoCV                                       \n",
    "lasso = LassoCV(cv=3)                                                   \n",
    "lasso.fit(feature_data_processed, class_data)                           \n",
    "coef = pandas.Series(lasso.coef_, index=feature_data_processed.columns) \n",
    "imp_coef = coef.sort_values()                                           \n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 20.0)                     \n",
    "imp_coef.plot(kind=\"barh\")                                              \n",
    "plot.title(\"Feature importance using Lasso Model\")                      \n",
    "plot.show()                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using ElasticNetCV\n",
    "    enet = ElasticNetCV(cv=3)\n",
    "    enet.fit(feature_data_processed, class_data)\n",
    "    coef = pandas.Series(enet.coef_, index=feature_data_processed.columns)\n",
    "    imp_coef = coef.sort_values()\n",
    "    matplotlib.rcParams['figure.figsize'] = (16.0, 20.0)\n",
    "    imp_coef.plot(kind=\"barh\")\n",
    "    plot.title(\"Feature importance using ElasticNet Model\")\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
